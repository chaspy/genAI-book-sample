# 5.5 ハイブリッド検索を実装する

ここまででベクトル検索による RAG が実現できました。次に先ほど学んだハイブリッド検索を実装しましょう。

## 5.5.1 EnsembleRetriever で統合する

実際にハイブリッド検索を実装してみましょう。LangChain の EnsembleRetriever（アンサンブルレトリーバー）を使えば、RRF（スコアリング）の計算も自動でやってくれます。プログラムは `scripts/chapter5/5-5-1-hybrid-search-rrf.py` を参照してください（サンプル文書は `scripts/chapter5/hybrid_sample_data/*.txt` を使用）。

### ソースコード（抜粋）

以下は `scripts/chapter5/5-5-1-hybrid-search-rrf.py` の主要部分のみを抜粋しています（インポートや .env 読み込み、結果保存などは省略）。全文はスクリプトを参照してください。

```python
def tokenize_for_bm25(text: str) -> list[str]:
    """日本語を含むテキストを軽量にトークナイズ（漢字・かなはbi-gram）。"""
    tokens = []
    for chunk in re.findall(r"[A-Za-z0-9]+|[一-龥ぁ-んァ-ンー]+", text):
        if re.fullmatch(r"[A-Za-z0-9]+", chunk):
            tokens.append(chunk)
        elif len(chunk) == 1:
            tokens.append(chunk)
        else:
            tokens.extend(chunk[i : i + 2] for i in range(len(chunk) - 1))
    return tokens

# サンプル文書の読み込みと分割（hybrid_sample_data/*.txt）
docs = […]  # Documentのリストを作成
splits = RecursiveCharacterTextSplitter(
    chunk_size=800, chunk_overlap=160
).split_documents(docs)

# BM25（キーワード検索）
bm25_retriever = BM25Retriever.from_documents(
    splits,
    preprocess_func=tokenize_for_bm25,
)
bm25_retriever.k = 8

# ベクトル検索
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=OpenAIEmbeddings(),
    collection_name="hybrid_demo",
)
dense_retriever = vectorstore.as_retriever(search_kwargs={"k": 8})

# EnsembleRetrieverでRRF融合
hybrid_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, dense_retriever],
    weights=[0.6, 1.0],
    c=60,
)

# LCEL でそのまま Retriever として利用可
prompt = PromptTemplate.from_template(
    "質問: {question}\nコンテキスト:\n{context}\n\n回答:"
)
rag_chain = (
    {"context": hybrid_retriever, "question": RunnablePassthrough()}
    | prompt
    | ChatOpenAI()
    | StrOutputParser()
)

query = "Elasticsearchの監視設定"
results = hybrid_retriever.invoke(query)
for i, doc in enumerate(results[:4]):
    title = doc.page_content.splitlines()[0]
    print(f"結果{i+1}: {doc.metadata.get('source')}: {title}")
```

EnsembleRetriever はそのまま LCEL パイプライン（「4 章 4.3.4Chain」参照）の Retriever として使用できるため、既存の RAG システムに簡単に組み込むことができます。

## 5.5.2 検索結果を比較分析する

まず、それぞれの検索手法の比較結果を見てみましょう。

**クエリ：『X-Pack monitoring の設定方法』**

=== 検索手法の比較 ===

BM25 検索結果

1. hybrid_doc_02.txt：Elasticsearch による高性能検索システムの実装　→ 製品名「X-Pack monitoring」でBM25が圧倒  
2. hybrid_doc_05.txt：RAG システムの最適化手法と実装戦略  
3. hybrid_doc_06.txt：LangChain の EnsembleRetriever による統合検索

ベクトル検索結果

1. hybrid_doc_02.txt：Elasticsearch による高性能検索システムの実装　→ 固有名詞が効きベクトルでも1位  
2. hybrid_doc_04.txt：開発者の生産性向上と創造的業務への集中  
3. hybrid_doc_01.txt：BM25 アルゴリズムの実装詳細

固有名詞を含む具体クエリでは BM25 が強みを発揮します。ベクトル検索でも 1 位は同じ文書になりますが、2〜3 位が一般論（doc04/01）に流れやすく、順位差で性質の違いが見えます。

**クエリ：『セマンティック検索のメリット』**

BM25 検索結果

1. hybrid_doc_02.txt：Elasticsearch による高性能検索システムの実装  
2. hybrid_doc_04.txt：開発者の生産性向上と創造的業務への集中  
3. hybrid_doc_05.txt：RAG システムの最適化手法と実装戦略

ベクトル検索結果

1. hybrid_doc_03.txt：検索技術の進化と意味理解の革命　→ 意味検索の意義を直接説明  
2. hybrid_doc_02.txt：Elasticsearch による高性能検索システムの実装  
3. hybrid_doc_05.txt：RAG システムの最適化手法と実装戦略

カタカナの「セマンティック」はコーパス内に明示されないため、BM25 は汎用的な「検索」語を多く含む doc02 に流れがち。一方ベクトル検索は意味類似で doc03（意味検索の解説）を1位に引き上げ、ベクトル優位な例となります。

では EnsembleRetriever でこれらを統合した結果を見てみましょう。

=== EnsembleRetriever（ハイブリッド検索）のデモ（実行結果） ===

クエリ：『X-Pack monitoring の設定方法』

ハイブリッド検索結果（上位 4 件）:

1. hybrid_doc_02.txt: Elasticsearch による高性能検索システムの実装
2. hybrid_doc_04.txt: 開発者の生産性向上と創造的業務への集中
3. hybrid_doc_05.txt: RAG システムの最適化手法と実装戦略
4. hybrid_doc_01.txt: BM25 アルゴリズムの実装詳細

クエリ：『セマンティック検索のメリット』

ハイブリッド検索結果（上位 4 件）:

1. hybrid_doc_02.txt: Elasticsearch による高性能検索システムの実装
2. hybrid_doc_03.txt: 検索技術の進化と意味理解の革命
3. hybrid_doc_05.txt: RAG システムの最適化手法と実装戦略
4. hybrid_doc_04.txt: 開発者の生産性向上と創造的業務への集中

両方の検索手法で上位にランクされた文書が、RRF によって総合的に高いスコアを得ています。これが「それぞれの意見を聞く」ハイブリッド検索の強みです。

## コラム：BM25 検索を日本語で扱う Tips

LangChain の BM25Retriever は標準だと `text.split()` で語を切り出すため、日本語のように空白が入らない文章ではうまく動きません。そこでサンプルコードでは正規表現ベースの軽量トークナイザ (`tokenize_for_bm25`) を用意し、`BM25Retriever.from_documents(..., preprocess_func=...)` に渡しています。

この 1 行を挟むだけで、文書とクエリの両方が同じルールで前処理され、「Elasticsearch の監視設定」のような固有名詞クエリでも BM25 が機能します。より精度を高めたい場合は、`tokenize_for_bm25` の中身を MeCab や SudachiPy を使った関数に差し替えることもできます。

## 5.5.3 重み付けパラメータを調整する

さらに興味深いのは、重み付け（weights）を変えることでの動作の変化です。「セマンティック検索のメリット」というクエリで見ていきましょう。

=== 重み付けの影響の確認 ===  
クエリ：「セマンティック検索のメリット」

上位 3 件の結果：

設定: BM25 重視 (BM25=0.9, Vector=0.1)

1. hybrid_doc_02.txt
2. hybrid_doc_04.txt
3. hybrid_doc_05.txt

設定: 均等 (BM25=0.5, Vector=0.5)

1. hybrid_doc_02.txt
2. hybrid_doc_03.txt
3. hybrid_doc_04.txt

設定: ベクトル重視 (BM25=0.1, Vector=0.9)

1. hybrid_doc_03.txt
2. hybrid_doc_02.txt
3. hybrid_doc_05.txt

1 位が BM25 重視では doc02、ベクトル重視では doc03 に入れ替わり、weights パラメータで主役が切り替わる様子が分かります。均等設定では両者の中間として doc02 がわずかに上位を保ちつつ doc03 が2位に躍り出ます。

## 5.5.4 実装のポイント

- 用途に応じた重み調整：技術文書なら BM25 を重視、FAQ ならベクトル検索を重視など、データの性質に応じて weights パラメータを調整することが重要です。
- RRF の k パラメータ：デフォルトの 60 は多くの場合うまく機能しますが、検索結果の数が少ない場合は調整が必要かもしれません。
- 検索数の設定：各 Retriever の top_k パラメータ（取得数）は最終的に必要な数より多めに設定し、RRF で統合後に絞り込むのが効果的です。

これで、キーワード検索の精度とベクトル検索の柔軟性を併せ持つ、頑健な RAG システムの検索部分が完成しました。
